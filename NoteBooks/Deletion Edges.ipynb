{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os.path\n",
    "import sys\n",
    "from os import path\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_features(dataset):\n",
    "    nodes_info = pd.read_csv(f\"{dataset}/nodeQualityFeatures.txt\", sep=\"\\t\")\n",
    "    nodes_info['out_homophily'] = [row['redNeighborsOutRatio'] if row['group'] == 1 else 1 - row['redNeighborsOutRatio']\n",
    "                               for i, row in nodes_info.iterrows()]\n",
    "    edges_scores = pd.read_csv(f\"{dataset}/deletion_scores.txt\")\n",
    "    df = edges_scores.join(nodes_info.set_index(\"nodeId\"), on=\"Source\", rsuffix=\"source\")\n",
    "    df = df.join(nodes_info.set_index(\"nodeId\"), on=\"Target\", lsuffix=\"_source\", rsuffix=\"_target\")\n",
    "    df = df.sort_values(axis=0, by=\"Score\", ascending=False)\n",
    "    df[\"red_pagerank_dif\"] = df[\"redPagerank_target\"] - df[\"redPagerank_source\"]\n",
    "    # 2 * a + 1 * b.\n",
    "    # 0: blue to blue, 1: blue to red, 2: red to blue, 3 red to red\n",
    "    df[\"edge_group\"] = (2 * df[\"group_source\"]) + df[\"group_target\"]\n",
    "    \n",
    "    # To get distances ##################\n",
    "    edges = [(i, j) for i,j in zip(df.Source, df.Target)]\n",
    "    f = open(f\"{dataset}/out_graph.txt\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    G = nx.parse_edgelist(lines[1:], nodetype=int, create_using=nx.DiGraph)\n",
    "    dist = list()\n",
    "    for e in edges:\n",
    "        try:\n",
    "            length = len(nx.shortest_path(G, source=e[1], target=e[0])) - 1\n",
    "            dist.append(length)\n",
    "        except nx.NetworkXNoPath:\n",
    "            dist.append(float(\"Inf\"))\n",
    "    df[\"Distance\"] = dist\n",
    "    #####################################\n",
    "    \n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = get_edge_features(\"books\")\n",
    "blogs = get_edge_features(\"blogs\")\n",
    "dblp = get_edge_features(\"dblp_course\")\n",
    "twitter = get_edge_features(\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\hline\n",
      "Metric & Books & Blogs & DBLP & Twitter & Books & Blogs & DBLP & Twitter \\\\\n",
      "\\hline\n",
      "pagerank_source & -0.0 & -0.0 & 0.0 & 0.03 & 0.02 & -0.12 & -0.04 & -0.0 \\\\\n",
      "\\hline\n",
      "redPagerank_source & -0.0 & -0.0 & -0.03 & 0.01 & 0.11 & 0.13 & -0.12 & 0.11 \\\\\n",
      "\\hline\n",
      "group_source & -0.0 & -0.0 & -0.03 & 0.01 & 0.24 & 0.11 & -0.02 & 0.06 \\\\\n",
      "\\hline\n",
      "inDegree_source & -0.0 & -0.0 & 0.0 & 0.01 & 0.03 & -0.08 & -0.01 & -0.01 \\\\\n",
      "\\hline\n",
      "outDegree_source & -0.0 & 0.0 & 0.0 & -0.0 & 0.03 & -0.03 & -0.01 & 0.03 \\\\\n",
      "\\hline\n",
      "redNeighborsInRatio_source & -0.0 & 0.0 & -0.03 & 0.0 & 0.18 & 0.14 & -0.17 & 0.06 \\\\\n",
      "\\hline\n",
      "redNeighborsOutRatio_source & -0.0 & -0.0 & -0.03 & 0.01 & 0.18 & 0.13 & -0.17 & 0.06 \\\\\n",
      "\\hline\n",
      "out_homophily_source & -0.0 & 0.0 & 0.03 & 0.02 & -0.27 & 0.02 & 0.13 & 0.01 \\\\\n",
      "\\hline\n",
      "pagerank_target & 0.01 & 0.02 & -0.02 & 0.01 & -0.11 & -0.02 & 0.05 & -0.07 \\\\\n",
      "\\hline\n",
      "redPagerank_target & 0.19 & 0.3 & 0.52 & 0.12 & 0.43 & 0.6 & 0.36 & 0.48 \\\\\n",
      "\\hline\n",
      "group_target & 0.23 & 0.22 & 0.69 & 0.03 & 0.34 & 0.38 & 0.59 & 0.11 \\\\\n",
      "\\hline\n",
      "inDegree_target & 0.02 & -0.06 & -0.02 & 0.0 & -0.1 & 0.05 & 0.07 & -0.07 \\\\\n",
      "\\hline\n",
      "outDegree_target & 0.02 & -0.1 & -0.02 & -0.01 & -0.1 & -0.16 & 0.07 & -0.13 \\\\\n",
      "\\hline\n",
      "redNeighborsInRatio_target & 0.19 & 0.15 & 0.13 & 0.03 & 0.39 & 0.3 & 0.17 & 0.04 \\\\\n",
      "\\hline\n",
      "redNeighborsOutRatio_target & 0.19 & 0.31 & 0.13 & 0.14 & 0.39 & 0.52 & 0.17 & 0.63 \\\\\n",
      "\\hline\n",
      "out_homophily_target & 0.07 & -0.01 & -0.6 & -0.04 & 0.08 & -0.12 & -0.46 & -0.09 \\\\\n",
      "\\hline\n",
      "red_pagerank_dif & 0.96 & 0.47 & 0.7 & 0.2 & 0.92 & 0.49 & 0.77 & 0.63 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "# Pearson.\n",
    "# Initialization and books.\n",
    "temp_cor = books.corr(method=\"pearson\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "values = list()\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values.append(str(label) + \" & \" + str(round(value, 2)))\n",
    "\n",
    "# Blogs.\n",
    "temp_cor = blogs.corr(method=\"pearson\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "\n",
    "# Dblp.\n",
    "temp_cor = dblp.corr(method=\"pearson\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "\n",
    "# Twitter.\n",
    "temp_cor = twitter.corr(method=\"pearson\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "\n",
    "# Spearman\n",
    "# Books.\n",
    "temp_cor = books.corr(method=\"spearman\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "# Blogs.\n",
    "temp_cor = blogs.corr(method=\"spearman\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "\n",
    "# Dblp.\n",
    "temp_cor = dblp.corr(method=\"spearman\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "\n",
    "# Twitter.\n",
    "temp_cor = twitter.corr(method=\"spearman\").Score[[\"pagerank_source\", \"redPagerank_source\", \"group_source\", \"inDegree_source\",\n",
    "                                               \"outDegree_source\", \"redNeighborsInRatio_source\", \"redNeighborsOutRatio_source\",\n",
    "                                               \"out_homophily_source\", \"pagerank_target\", \"redPagerank_target\", \"group_target\",\n",
    "                                               \"inDegree_target\", \"outDegree_target\", \"redNeighborsInRatio_target\",\n",
    "                                               \"redNeighborsOutRatio_target\", \"out_homophily_target\", \"red_pagerank_dif\"]]\n",
    "\n",
    "i = 0\n",
    "for label, value in temp_cor.iteritems():\n",
    "    values[i] += \" & \" + str(round(value, 2))\n",
    "    i += 1\n",
    "\n",
    "# Print latex table.\n",
    "print(\"\\\\hline\")\n",
    "print(\"Metric & Books & Blogs & DBLP & Twitter & Books & Blogs & DBLP & Twitter \\\\\\\\\")\n",
    "print(\"\\\\hline\")\n",
    "for i in values:\n",
    "    print(i + \" \\\\\\\\\")\n",
    "    print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_names = pd.read_csv(\"dblp_course/names.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_best = dblp.head(20)[[\"Source\", \"Target\", \"Score\"]]\n",
    "df_best = dblp_best.join(dblp_names.set_index(\"Node_id\"), on=\"Source\", rsuffix=\"source\" )\n",
    "df_best = df_best.join(dblp_names.set_index(\"Node_id\"), on=\"Target\", lsuffix=\"_Source\", rsuffix=\"_Target\")\n",
    "dblp_worst = dblp.tail(20)[[\"Source\", \"Target\", \"Score\"]]\n",
    "df_worst = dblp_worst.join(dblp_names.set_index(\"Node_id\"), on=\"Source\", rsuffix=\"source\" )\n",
    "df_worst = df_worst.join(dblp_names.set_index(\"Node_id\"), on=\"Target\", lsuffix=\"_Source\", rsuffix=\"_Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_best[[\"Author_Name_Source\", \"Author_Name_Target\", \"Score\"]]\n",
    "df_worst = df_worst[[\"Author_Name_Source\", \"Author_Name_Target\", \"Score\"]].sort_values(axis=0, by=\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\hline\n",
      "Order & Source & Target & Score & Source & Target & Score\n",
      "\\hline\n",
      "1 & Hassan Sayyadi & Lise Getoor & 4.3e-05 & Valeria De Antonellis & Silvana Castano & -6.7e-05\\\\\n",
      "\\hline\n",
      "2 & Blake Anderson & Susan T. Dumais & 4.3e-05 & Tevfik Bultan & Richard Hull & -5.6e-05\\\\\n",
      "\\hline\n",
      "3 & Michel E. Adiba & Christine Collet & 3.6e-05 & Mizuho Iwaihara & Mukesh K. Mohania & -5.2e-05\\\\\n",
      "\\hline\n",
      "4 & Wendy Hall & Leslie Carr & 3.3e-05 & Lionel Martin & Guillaume Cleuziou & -3.9e-05\\\\\n",
      "\\hline\n",
      "5 & Ratko Orlandic & Martha W. Evens & 3.2e-05 & Hassina Meziane & Mike P. Papazoglou & -3.8e-05\\\\\n",
      "\\hline\n",
      "6 & Hassina Meziane & Salima Benbernou & 2.9e-05 & Jennifer L. Gardy & Martin Ester & -3.6e-05\\\\\n",
      "\\hline\n",
      "7 & Michael Klein & Birgitta Konig-Ries & 2.8e-05 & Karen C. Davis & Alfredo Cuzzocrea & -3.6e-05\\\\\n",
      "\\hline\n",
      "8 & Mirco Stern & Birgitta Konig-Ries & 2.8e-05 & Marilyn Crilley & David Brill & -3.4e-05\\\\\n",
      "\\hline\n",
      "9 & George H. L. Fletcher & Alexandra Poulovassilis & 2.7e-05 & Igor Canadi & Paul Barford & -3e-05\\\\\n",
      "\\hline\n",
      "10 & Lionel Martin & Valentina Sintsova & 2.7e-05 & Ben Y. Zhao & Amr El Abbadi & -3e-05\\\\\n",
      "\\hline\n",
      "11 & Lionel Martin & Pearl Pu & 2.7e-05 & Doina Precup & Robert West 0001 & -3e-05\\\\\n",
      "\\hline\n",
      "12 & Joan Serra & Emilia Gomez & 2.7e-05 & Simone Teufel & Stephen Robertson & -2.9e-05\\\\\n",
      "\\hline\n",
      "13 & James Decraene & Amy Shi Nash & 2.5e-05 & Joseph G. Ellis & David M. Blei & -2.9e-05\\\\\n",
      "\\hline\n",
      "14 & Mouna Torjmen & Mariam Daoud & 2.5e-05 & Elaine G. Toms & Charles L. A. Clarke & -2.8e-05\\\\\n",
      "\\hline\n",
      "15 & Byron C. Wallace & Carla E. Brodley & 2.4e-05 & Felix Leif Keppmann & Andreas Harth & -2.7e-05\\\\\n",
      "\\hline\n",
      "16 & Ron Obermarck & Catriel Beeri & 2.4e-05 & Sherry Emery & Arjun Mukherjee & -2.7e-05\\\\\n",
      "\\hline\n",
      "17 & Igor Canadi & Darja Krushevskaja & 2.3e-05 & Di Wang & Jeffrey F. Naughton & -2.6e-05\\\\\n",
      "\\hline\n",
      "18 & Joseph G. Ellis & Maja R. Rudolph & 2.3e-05 & Jonathan Yu & James A. Thom & -2.6e-05\\\\\n",
      "\\hline\n",
      "19 & Marilyn Crilley & Iris Kameny & 2.3e-05 & Leonardo Vilela Teixeira & Renato Martins Assuncao & -2.6e-05\\\\\n",
      "\\hline\n",
      "20 & Jennifer L. Gardy & Fiona S. L. Brinkman & 2.3e-05 & James Decraene & Manoranjan Dash & -2.6e-05\\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "latex_table = list()\n",
    "i = 0\n",
    "for index, row in df_best.iterrows():\n",
    "    latex_table.append(str(i + 1))\n",
    "    for label, value in row.iteritems():\n",
    "        value_t = round(value, 6) if type(value) is float else value\n",
    "        latex_table[i] += \" & \" + str(value_t)\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "for index, row in df_worst.iterrows():\n",
    "    for label, value in row.iteritems():\n",
    "        value_t = round(value, 6) if type(value) is float else value\n",
    "        latex_table[i] += \" & \" + str(value_t)\n",
    "    i += 1\n",
    "\n",
    "# Print table in latex code.\n",
    "print(\"\\\\hline\")\n",
    "print(\"Order & Source & Target & Score & Source & Target & Score\")\n",
    "print(\"\\\\hline\")\n",
    "for row in latex_table:\n",
    "    print(row + \"\\\\\\\\\")\n",
    "    print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
